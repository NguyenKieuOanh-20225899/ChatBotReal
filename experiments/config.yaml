paths:
  chunks_dir: "data/chunks"
  kb_dir: "data/knowledge_base"
  artifacts_dir: "experiments/artifacts"
  devset_path: "experiments/devset/dev_100.jsonl"

index:
  embedding_model: "intfloat/multilingual-e5-base"
  faiss_nlist: 100 # Giảm xuống nếu dữ liệu ít (<10k chunks) để tránh warning
  faiss_nprobe: 10

retrieval:
  bm25_topk: 50
  dense_topk: 50
  rrf_K: 60
  # Đây là số lượng kết quả mặc định trả về nếu không chỉ định k. 
  # (Script run_E3_reranker.py sẽ override lên 100 để lọc kỹ hơn).
  final_topk: 20 
  
  # [Quan trọng] Trọng số [BM25, Vector]. 
  # Đặt BM25 = 2.0 để ưu tiên từ khóa chính xác (Số hiệu luật, tên điều khoản).
  rrf_weights: [2.0, 1.0]

reranker:
  # [Khuyên dùng] Model BAAI hỗ trợ tiếng Việt và Multilingual rất mạnh (State-of-the-art)
  # Yêu cầu cài đặt: pip install FlagEmbedding
  model_name: "BAAI/bge-reranker-v2-m3" 
  
  # Model dự phòng (nhẹ hơn nhưng kém chính xác hơn với tiếng Việt):
  # model_name: "amberoad/bert-multilingual-passage-reranking-msmarco"
  
  apply: true
  keep_topk: 5 # Số lượng chunk cuối cùng đưa vào LLM để trả lời

thresholds:
  answerability_min_score: 0.5 # Ngưỡng tin cậy