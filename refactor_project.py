import os
import shutil
from pathlib import Path

# --- C·∫§U H√åNH ---
BASE_DIR = Path(__file__).parent.absolute()

# ƒê·ªãnh nghƒ©a c√°c th∆∞ m·ª•c m·ªõi c·∫ßn t·∫°o
NEW_DIRS = [
    "config",
    "logs",
    "src",
    "src/core",
    "src/services",
    "src/utils",
    "data/artifacts", # Chuy·ªÉn artifacts v√†o data
]

# N·ªôi dung cho c√°c file __init__.py
INIT_CONTENT = ""

# --- N·ªòI DUNG C√ÅC FILE M·ªöI (CLEAN CODE) ---

# 1. config/config.yaml (C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n)
CONFIG_CONTENT = """paths:
  chunks_dir: "data/chunks"
  kb_dir: "data/knowledge_base"
  artifacts_dir: "data/artifacts"
  devset_path: "experiments/devset/dev_100.jsonl"

index:
  embedding_model: "intfloat/multilingual-e5-base"
  faiss_nlist: 100
  faiss_nprobe: 10

retrieval:
  bm25_topk: 50
  dense_topk: 50
  rrf_K: 60
  final_topk: 20
  rrf_weights: [2.0, 1.0]

reranker:
  model_name: "BAAI/bge-reranker-v2-m3"
  apply: true
  keep_topk: 5

thresholds:
  answerability_min_score: 0.5
"""

# 2. src/services/retrieval_service.py
RETRIEVAL_SERVICE_CONTENT = """import os
import yaml
from typing import List, Dict
from src.core.search_engine import HybridSearcher
from src.core.reranker import CrossEncoderReranker

class LegalRetriever:
    def __init__(self, config_path: str = "config/config.yaml"):
        print("üîÑ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng t√¨m ki·∫øm (LegalRetriever)...")

        self.config_path = os.path.abspath(config_path)
        if not os.path.exists(self.config_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y config t·∫°i: {self.config_path}")

        self.cfg = yaml.safe_load(open(self.config_path, "r", encoding="utf-8"))

        # 1. Load Searcher
        self.searcher = HybridSearcher(self.cfg)

        # 2. Load Reranker
        rerank_cfg = self.cfg.get("reranker", {})
        self.reranker = CrossEncoderReranker(rerank_cfg.get("model_name", "BAAI/bge-reranker-v2-m3"))
        self.keep_topk = rerank_cfg.get("keep_topk", 5)

        print("‚úÖ LegalRetriever ƒë√£ s·∫µn s√†ng!")

    def retrieve(self, query: str) -> List[str]:
        candidates = self.searcher.search(query)

        if self.cfg.get("reranker", {}).get("apply", False):
            reranked_results, _ = self.reranker.rerank(query, candidates, keep_topk=self.keep_topk)
        else:
            reranked_results = candidates[:self.keep_topk]

        context_list = []
        for item in reranked_results:
            doc_text = item.get("doc", "")
            source = item.get("meta", {}).get("source_file", "Unknown")
            context_list.append(f"[{source}]: {doc_text}")

        return context_list
"""

# 3. src/services/graph_rag_service.py
GRAPH_RAG_SERVICE_CONTENT = """import os
import re
import time
from typing import Tuple, Any

import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from neo4j import GraphDatabase
from dotenv import load_dotenv

class GraphRAGService:
    def __init__(self, vector_db_path: str = "data/vector_db"):
        load_dotenv()
        self.api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("API Key not found in environment variables.")

        genai.configure(api_key=self.api_key)

        self.neo4j_uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
        self.neo4j_user = os.getenv("NEO4J_USERNAME", "neo4j")
        self.neo4j_pass = os.getenv("NEO4J_PASSWORD", "password")
        self.driver = GraphDatabase.driver(self.neo4j_uri, auth=(self.neo4j_user, self.neo4j_pass))

        self.model = genai.GenerativeModel("gemini-2.0-flash")
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            google_api_key=self.api_key
        )

        try:
            self.vector_db = FAISS.load_local(vector_db_path, self.embeddings, allow_dangerous_deserialization=True)
            print("‚úÖ Vector DB loaded.")
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not load Vector DB at {vector_db_path}. Error: {e}")
            self.vector_db = None

    def close(self):
        if self.driver:
            self.driver.close()

    def query(self, query_text: str, k: int = 5) -> Tuple[str, dict, float]:
        t0 = time.perf_counter()

        ctx_vec = ""
        vec_sources = []
        article_ids = []

        if self.vector_db:
            hits = self.vector_db.similarity_search(query_text, k=k)
            ctx_vec = "\\n\\n".join(h.page_content for h in hits)
            vec_sources = [h.metadata.get("source") for h in hits]
            found_ids = re.findall(r"ƒêi·ªÅu\s+\d+", ctx_vec, flags=re.IGNORECASE)
            article_ids = list({a.strip() for a in found_ids})[:10]

        extract_resp = self.model.generate_content(
            f"T·ª´ c√¢u h·ªèi sau, li·ªát k√™ t·ªëi ƒëa 5 kh√°i ni·ªám ph√°p l√Ω c·ªët l√µi (m·ªói d√≤ng 1 m·ª•c, kh√¥ng gi·∫£i th√≠ch):\\n{query_text}"
        )
        concepts = [x.strip("-‚Ä¢ \\n") for x in extract_resp.text.splitlines() if x.strip()][:5]

        edges = self._query_neo4j(article_ids, concepts)

        ctx_graph = "\\n".join(f"{e['from_id']} {e['rel']} {e['to_id']} ({e.get('topic','')})" for e in edges)
        if not ctx_graph:
            ctx_graph = "Kh√¥ng c√≥ th√¥ng tin t·ª´ ƒë·ªì th·ªã."

        prompt = f'''
B·∫°n l√† tr·ª£ l√Ω ph√°p l√Ω Vi·ªát Nam. D·ª±a v√†o ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, tr·∫£ l·ªùi ch√≠nh x√°c, c√≥ d·∫´n ƒêi·ªÅu/kho·∫£n n·∫øu c√≥.

[C√¢u h·ªèi]
{query_text}

[ƒêo·∫°n vƒÉn ph√°p lu·∫≠t (Vector)]
{ctx_vec}

[Quan h·ªá ph√°p l√Ω (Graph)]
{ctx_graph}
'''
        response = self.model.generate_content(prompt)
        latency = time.perf_counter() - t0

        meta = {
            "concepts": concepts,
            "vector_sources": vec_sources,
            "graph_edges": edges,
            "article_ids_from_vector": article_ids
        }

        return response.text, meta, latency

    def _query_neo4j(self, article_ids: list, concepts: list) -> list:
        edges = []
        with self.driver.session() as sess:
            if article_ids:
                res1 = sess.run(\"\"\"
                    MATCH (a:Article)-[r:RELATED]-(b:Article)
                    WHERE a.id IN $ids
                    RETURN a.id AS from_id, b.id AS to_id, coalesce(r.relation,'RELATED') AS rel, b.topic AS topic
                    LIMIT 50
                \"\"\", ids=article_ids)
                edges += [dict(r) for r in res1]

            if len(edges) < 5 and concepts:
                res2 = sess.run(\"\"\"
                    MATCH (a:Article)-[r:RELATED]->(b:Article)
                    WHERE any(c IN $concepts WHERE toLower(a.topic) CONTAINS toLower(c))
                       OR any(c IN $concepts WHERE toLower(b.topic) CONTAINS toLower(c))
                    RETURN a.id AS from_id, b.id AS to_id, coalesce(r.relation,'RELATED') AS rel, b.topic AS topic
                    LIMIT 25
                \"\"\", concepts=[c.lower() for c in concepts])
                edges += [dict(r) for r in res2]
        return edges
"""

# 4. scripts/run_cli_chat.py
RUN_CLI_CONTENT = """import sys
import os

# Th√™m root project v√†o sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.services.graph_rag_service import GraphRAGService

def main():
    print("üöÄ ƒêang kh·ªüi t·∫°o Chatbot GraphRAG...")
    try:
        bot = GraphRAGService(vector_db_path="data/vector_db")
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
        return

    print("‚úÖ S·∫µn s√†ng! Nh·∫≠p 'exit' ƒë·ªÉ tho√°t.")
    while True:
        try:
            query = input("\\n‚ùì Nh·∫≠p c√¢u h·ªèi ph√°p lu·∫≠t: ").strip()
            if query.lower() in ["exit", "quit", "tho√°t"]:
                break
            if not query:
                continue

            answer, meta, latency = bot.query(query)

            print("\\n=== TR·∫¢ L·ªúI ===")
            print(answer)
            print(f"\\n‚è±Ô∏è Th·ªùi gian: {latency:.2f}s")
            print(f"üìä Metadata: {len(meta['graph_edges'])} c·∫°nh ƒë·ªì th·ªã, {len(meta['vector_sources'])} ngu·ªìn vector.")

        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω: {e}")

    bot.close()
    print("\\nTam bi·ªát!")

if __name__ == "__main__":
    main()
"""

# --- H√ÄM H·ªñ TR·ª¢ ---

def create_directory_structure():
    print("üìÇ ƒêang t·∫°o c·∫•u tr√∫c th∆∞ m·ª•c...")
    for d in NEW_DIRS:
        path = BASE_DIR / d
        path.mkdir(parents=True, exist_ok=True)
        # T·∫°o __init__.py cho c√°c folder src
        if d.startswith("src"):
            (path / "__init__.py").write_text(INIT_CONTENT)

def move_and_patch_file(src_path: Path, dest_path: Path, replacements: dict):
    """Di chuy·ªÉn file v√† thay th·∫ø n·ªôi dung (imports)"""
    if not src_path.exists():
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file g·ªëc: {src_path}. B·ªè qua.")
        return

    print(f"üöö Di chuy·ªÉn & Patch: {src_path.name} -> {dest_path}")
    content = src_path.read_text(encoding="utf-8")

    # Th·ª±c hi·ªán thay th·∫ø c√°c chu·ªói import c≈©
    for old, new in replacements.items():
        content = content.replace(old, new)

    dest_path.write_text(content, encoding="utf-8")

def write_new_file(path: Path, content: str):
    print(f"üìù T·∫°o file m·ªõi: {path}")
    path.write_text(content, encoding="utf-8")

def move_artifacts():
    """Di chuy·ªÉn c√°c file trong experiments/artifacts sang data/artifacts"""
    src_dir = BASE_DIR / "experiments" / "artifacts"
    dest_dir = BASE_DIR / "data" / "artifacts"

    if src_dir.exists():
        print("üì¶ ƒêang di chuy·ªÉn Artifacts...")
        for item in src_dir.iterdir():
            if item.is_file():
                shutil.copy2(item, dest_dir / item.name)
        print("‚úÖ ƒê√£ di chuy·ªÉn Artifacts xong.")
    else:
        print("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c artifacts c≈©.")

# --- MAIN EXECUTION ---

def main():
    print("üöÄ B·∫Øt ƒë·∫ßu Refactor Project...")

    # 1. T·∫°o th∆∞ m·ª•c
    create_directory_structure()

    # 2. T·∫°o Config m·ªõi
    write_new_file(BASE_DIR / "config/config.yaml", CONFIG_CONTENT)

    # 3. Move & Patch c√°c file Core t·ª´ experiments
    # Map ƒë·ªïi t√™n import
    core_replacements = {
        "from experiments.text_utils": "from src.utils.text_utils",
        "from experiments.rerank": "from src.core.reranker",
        "from experiments.search_pipeline": "from src.core.search_engine",
        "import experiments.config": "import config"
    }

    # experiments/search_pipeline.py -> src/core/search_engine.py
    move_and_patch_file(
        BASE_DIR / "experiments/search_pipeline.py",
        BASE_DIR / "src/core/search_engine.py",
        core_replacements
    )

    # experiments/rerank.py -> src/core/reranker.py
    move_and_patch_file(
        BASE_DIR / "experiments/rerank.py",
        BASE_DIR / "src/core/reranker.py",
        core_replacements
    )

    # experiments/text_utils.py -> src/utils/text_utils.py
    move_and_patch_file(
        BASE_DIR / "experiments/text_utils.py",
        BASE_DIR / "src/utils/text_utils.py",
        core_replacements
    )

    # 4. T·∫°o c√°c file Services m·ªõi (Code ƒë√£ refactor ho√†n ch·ªânh)
    write_new_file(BASE_DIR / "src/services/retrieval_service.py", RETRIEVAL_SERVICE_CONTENT)
    write_new_file(BASE_DIR / "src/services/graph_rag_service.py", GRAPH_RAG_SERVICE_CONTENT)

    # 5. T·∫°o Script ch·∫°y
    write_new_file(BASE_DIR / "scripts/run_cli_chat.py", RUN_CLI_CONTENT)

    # 6. Di chuy·ªÉn d·ªØ li·ªáu artifacts (indexes)
    move_artifacts()

    print("\nüéâ Refactor ho√†n t·∫•t!")
    print("üëâ B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y: python scripts/run_cli_chat.py")
    print("‚ö†Ô∏è L∆∞u √Ω: H√£y ki·ªÉm tra k·ªπ l·∫°i file .env c·ªßa b·∫°n.")

if __name__ == "__main__":
    main()
