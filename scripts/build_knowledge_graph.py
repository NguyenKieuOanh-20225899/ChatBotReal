# File: scripts/build_knowledge_graph.py
import os
import json
import re
import time
from glob import glob
from tqdm import tqdm
from dotenv import load_dotenv
from langchain_groq import ChatGroq

# Load mÃ´i trÆ°á»ng
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    print("âŒ Lá»–I: ChÆ°a cÃ³ GROQ_API_KEY trong file .env")
    exit(1)

# --- Cáº¬P NHáº¬T MODEL Má»šI Táº I ÄÃ‚Y ---
# Model cÅ© 'llama3-70b-8192' Ä‘Ã£ bá»‹ xÃ³a.
# DÃ¹ng 'llama-3.3-70b-versatile' (Máº¡nh nháº¥t) hoáº·c 'llama-3.1-8b-instant' (Nhanh nháº¥t)
llm = ChatGroq(
    api_key=GROQ_API_KEY,
    model_name="llama-3.3-70b-versatile",
    temperature=0.1,
    max_retries=3
)

CHUNKS_DIR = "data/chunks"
OUTPUT_FILE = "data/knowledge_graph.json"

def extract_article_id(text):
    """
    Láº¥y ID: 'Äiá»u 5', 'Äiá»u 13a' tá»« vÄƒn báº£n.
    """
    match = re.search(r"^(Äiá»u \d+[a-z]*)\b", text, re.IGNORECASE)
    if match:
        raw_id = match.group(1)
        # Chuáº©n hÃ³a: "Ä‘iá»u 5a" -> "Äiá»u 5a"
        return raw_id.capitalize().replace("Ä‘iá»u", "Äiá»u")
    return None

def get_ai_summary(text, retry_count=0):
    """
    DÃ¹ng Groq Ä‘á»ƒ tÃ³m táº¯t ná»™i dung Ä‘iá»u luáº­t.
    CÃ³ cÆ¡ cháº¿ thá»­ láº¡i thá»§ cÃ´ng náº¿u gáº·p lá»—i Rate Limit.
    """
    try:
        prompt = f"""
        Nhiá»‡m vá»¥: TÃ³m táº¯t ná»™i dung chÃ­nh cá»§a vÄƒn báº£n luáº­t dÆ°á»›i Ä‘Ã¢y thÃ nh 1 cá»¥m danh tá»« ngáº¯n gá»n (dÆ°á»›i 15 tá»«).
        KhÃ´ng dÃ¹ng dáº¥u ngoáº·c kÃ©p. KhÃ´ng giáº£i thÃ­ch dÃ i dÃ²ng.

        VÄƒn báº£n:
        {text[:800]}

        TÃ³m táº¯t:
        """
        response = llm.invoke(prompt)
        return response.content.strip().replace('"', '').replace("TÃ³m táº¯t:", "").strip()
    except Exception as e:
        error_msg = str(e)
        # Náº¿u lá»—i do Rate Limit (429), thá»­ Ä‘á»£i vÃ  gá»i láº¡i
        if "429" in error_msg or "Rate limit" in error_msg:
            if retry_count < 3:
                wait_time = (retry_count + 1) * 5 # Äá»£i 5s, 10s, 15s
                print(f"âš ï¸ QuÃ¡ táº£i API (Rate Limit), Ä‘ang Ä‘á»£i {wait_time}s Ä‘á»ƒ thá»­ láº¡i...")
                time.sleep(wait_time)
                return get_ai_summary(text, retry_count + 1)

        print(f"âŒ Lá»—i Groq khi tÃ³m táº¯t: {error_msg}")
        # Láº¥y dÃ²ng Ä‘áº§u tiÃªn lÃ m fallback
        lines = text.split('\n')
        fallback = lines[0][:50] + "..." if lines else "Ná»™i dung Ä‘iá»u luáº­t (Lá»—i AI)"
        return fallback

def build_graph():
    nodes = {}
    edges = []

    files = glob(os.path.join(CHUNKS_DIR, "*.json"))
    print(f"ğŸ—ï¸  Äang xÃ¢y dá»±ng Knowledge Graph tá»« {len(files)} file...")
    print("âš¡ Äang sá»­ dá»¥ng Groq API (Llama 3.3) Ä‘á»ƒ trÃ­ch xuáº¥t Topic...")

    request_count = 0

    for filepath in tqdm(files):
        with open(filepath, 'r', encoding='utf-8') as f:
            chunks = json.load(f)

        for chunk in chunks:
            # 1. Láº¥y ná»™i dung vÃ  metadata
            if isinstance(chunk, dict):
                content = chunk.get("page_content", "")
                meta = chunk.get("metadata", {})
                source = meta.get("source", os.path.basename(filepath))
            else:
                content = str(chunk)
                source = os.path.basename(filepath)

            # 2. XÃ¡c Ä‘á»‹nh ID Node (Äiá»u luáº­t)
            node_id = extract_article_id(content)
            if not node_id:
                continue

            # 3. Táº¡o Node hoáº·c Cáº­p nháº­t Node
            should_update_topic = False

            if node_id not in nodes:
                nodes[node_id] = {
                    "id": node_id,
                    "topic": "",
                    "type": "Article",
                    "sources": [source]
                }
                should_update_topic = True
            else:
                if nodes[node_id].get("topic") == "Äang cáº­p nháº­t":
                    should_update_topic = True
                if source not in nodes[node_id]["sources"]:
                    nodes[node_id]["sources"].append(source)

            # 4. Gá»i AI Update Topic (Náº¿u cáº§n)
            if should_update_topic:
                topic = get_ai_summary(content)
                nodes[node_id]["topic"] = topic

                # Rate Limit thá»§ cÃ´ng
                request_count += 1
                if request_count % 10 == 0:
                    time.sleep(2)

            # 5. Táº¡o Edges
            refs = re.findall(r"Äiá»u (\d+[a-z]*)", content, re.IGNORECASE)
            for r in refs:
                target_id = f"Äiá»u {r}"
                if target_id.lower() != node_id.lower():
                    edge = {
                        "from": node_id,
                        "to": target_id,
                        "relation": "dáº«n chiáº¿u Ä‘áº¿n"
                    }
                    if edge not in edges:
                        edges.append(edge)

                    if target_id not in nodes:
                        nodes[target_id] = {
                            "id": target_id,
                            "topic": "Äang cáº­p nháº­t",
                            "type": "Article",
                            "sources": []
                        }

    # LÆ°u káº¿t quáº£
    graph_data = {"nodes": list(nodes.values()), "edges": edges}
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… HoÃ n táº¥t! ÄÃ£ lÆ°u táº¡i {OUTPUT_FILE}")
    print(f"   - Nodes: {len(nodes)}")
    print(f"   - Edges: {len(edges)}")

if __name__ == "__main__":
    build_graph()
