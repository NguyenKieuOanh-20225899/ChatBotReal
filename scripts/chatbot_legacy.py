# scripts/chatbot_legacy.py
import os, time
import sys

# Th√™m ƒë∆∞·ªùng d·∫´n root ƒë·ªÉ tr√°nh l·ªói import n·∫øu c·∫ßn
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai

# Load API Key
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")
if not API_KEY:
    print("‚ùå L·ªói: Ch∆∞a c√≥ GOOGLE_API_KEY trong .env")
    sys.exit(1)

genai.configure(api_key=API_KEY)

# --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# L∆∞u √Ω: ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√≥ vector_db c≈© ·ªü ƒë√¢y.
# N·∫øu b·∫°n ƒë√£ x√≥a folder vector_db ƒë·ªÉ ch·∫°y c√°i m·ªõi th√¨ code n√†y s·∫Ω l·ªói.
# N·∫øu l·ªói, b·∫°n c·∫ßn tr·ªè ƒë√∫ng ƒë∆∞·ªùng d·∫´n ho·∫∑c ch·∫°y l·∫°i script t·∫°o vector c≈©.
VECTOR_DIR = os.path.join(BASE_DIR, "data", "vector_db")

# Init Model
embedding = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004",
    google_api_key=API_KEY
)

# Th·ª≠ load vector db, n·∫øu kh√¥ng c√≥ th√¨ b√°o l·ªói
try:
    vector_db = FAISS.load_local(VECTOR_DIR, embedding, allow_dangerous_deserialization=True)
except Exception as e:
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y Vector DB c≈© t·∫°i {VECTOR_DIR}.")
    print("B·∫°n c√≥ th·ªÉ c·∫ßn ch·∫°y l·∫°i script t·∫°o vector c≈© (n·∫øu ƒë√£ l·ª° x√≥a) ƒë·ªÉ test.")
    sys.exit(1)

model = genai.GenerativeModel("gemini-2.0-flash")

def query_vector(query: str, k: int = 5):
    """Vector-only RAG (H·ªá th·ªëng C≈©)."""
    t0 = time.perf_counter()

    # 1. Ch·ªâ t√¨m ki·∫øm b·∫±ng Vector (Semantic Search)
    results = vector_db.similarity_search(query, k=k)

    context = "\n\n".join(r.page_content for r in results)

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ph√°p l√Ω am hi·ªÉu lu·∫≠t Vi·ªát Nam.
H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c v√† c√≥ d·∫´n ƒêi·ªÅu lu·∫≠t li√™n quan.

C√¢u h·ªèi: {query}

C√°c ƒëo·∫°n lu·∫≠t tham kh·∫£o:
{context}
"""
    # 2. G·ªçi Gemini tr·∫£ l·ªùi
    resp = model.generate_content(prompt)

    latency = time.perf_counter() - t0
    sources = [r.metadata.get("source", "Unknown") for r in results]
    return resp.text, sources, latency

if __name__ == "__main__":
    print("ü§ñ CHATBOT C≈® (Vector Search Only)")
    print("----------------------------------")
    while True:
        q = input("\nüë§ Nh·∫≠p c√¢u h·ªèi (old bot): ")
        if q.lower() in ["exit", "quit"]:
            break

        ans, srcs, t = query_vector(q)
        print("\nü§ñ Tr·∫£ l·ªùi:")
        print(ans)
        print("\nüìö Ngu·ªìn tham kh·∫£o (Top 5 Vector):")
        for s in srcs: print("‚Üí", s)
        print(f"\n‚ö° Latency: {t:.2f}s")