import streamlit as st
import sys
import os
import time

# 1. C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n (gi·ªëng nh∆∞ trong run_cli_chat.py)
# Th√™m root project v√†o sys.path ƒë·ªÉ import ƒë∆∞·ª£c src
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.services.graph_rag_service import GraphRAGService

# 2. C·∫•u h√¨nh trang Streamlit
st.set_page_config(
    page_title="Tr·ª£ l√Ω Lu·∫≠t s∆∞ AI",
    page_icon="",
    layout="centered"
)

st.title(" Tr·ª£ l√Ω Lu·∫≠t s∆∞ AI (GraphRAG)")
st.caption("H·ªèi ƒë√°p ph√°p lu·∫≠t d·ª±a tr√™n VƒÉn b·∫£n ph√°p quy & Knowledge Graph")

# 3. Kh·ªüi t·∫°o Bot (S·ª≠ d·ª•ng cache ƒë·ªÉ kh√¥ng ph·∫£i load l·∫°i Model/Vector DB m·ªói l·∫ßn reload trang)
@st.cache_resource
def load_chatbot():
    # S·ª≠ d·ª•ng ƒë√∫ng ƒë∆∞·ªùng d·∫´n nh∆∞ trong file CLI c≈©
    return GraphRAGService(
        vector_db_path="data/artifacts",
        graph_path="data/knowledge_graph.json"
    )

try:
    with st.spinner("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng (Loading Vector DB & Graph)..."):
        bot = load_chatbot()
    st.success("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!", icon="‚úÖ")
except Exception as e:
    st.error(f"L·ªói kh·ªüi t·∫°o: {e}")
    st.stop()

# 4. Qu·∫£n l√Ω l·ªãch s·ª≠ chat (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # N·∫øu c√≥ metadata (ngu·ªìn) ƒëi k√®m trong tin nh·∫Øn c≈©, hi·ªÉn th·ªã l·∫°i (n·∫øu l∆∞u)
        if "meta_info" in message:
            st.caption(message["meta_info"])

# 5. X·ª≠ l√Ω input t·ª´ ng∆∞·ªùi d√πng
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi ph√°p lu·∫≠t c·ªßa b·∫°n..."):
    # Hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # X·ª≠ l√Ω tr·∫£ l·ªùi
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        try:
            # G·ªçi h√†m query t·ª´ service c·ªßa b·∫°n
            # H√†m tr·∫£ v·ªÅ: answer, meta, latency (theo file run_cli_chat.py)
            answer, meta, latency = bot.query(prompt)

            message_placeholder.markdown(answer)

            # X·ª≠ l√Ω hi·ªÉn th·ªã Metadata (Ngu·ªìn tr√≠ch d·∫´n)
            n_graph = meta.get('graph_edges_used', 0)
            vector_sources = meta.get('vector_sources', [])
            n_vector = len(vector_sources)

            # T·∫°o chu·ªói th√¥ng tin ph·ª•
            meta_info = f"‚è±Ô∏è Th·ªùi gian: {latency:.2f}s | üìä Graph edges: {n_graph} | üìÑ Vector docs: {n_vector}"
            if n_vector > 0:
                # L·∫•y t√™n c√°c ngu·ªìn (lo·∫°i b·ªè tr√πng l·∫∑p)
                sources_list = list(set(vector_sources))
                meta_info += f"\n\nüìö Ngu·ªìn tham kh·∫£o: {', '.join(sources_list[:3])}"
                if len(sources_list) > 3:
                    meta_info += "..."

            st.caption(meta_info)

            # L∆∞u v√†o l·ªãch s·ª≠ chat
            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "meta_info": meta_info
            })

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
